# Homework 2: Transformer Architecture Ablation Study

**Course**: Deep Learning for Finance
**Due Date**: November 10, 2025 (11:59 PM)
**Total Points**: 100 points

---

## Assignment Overview

In Homework 2 you will design, run, and analyze an ablation study comparing three Transformer architectures for univariate time-series forecasting. All helper utilities are bundled inside the assignment notebook—no extra Python files are required.

You will generate synthetic datasets, prepare data loaders, train multiple models with early stopping, and interpret results through tables, plots, and hypothesis-driven analysis.

---

## Learning Objectives

- Practice building reproducible time-series experiments with Transformers.
- Understand encoder-decoder, encoder-only, and decoder-only design trade-offs.
- Evaluate models with MAE/RMSE, parameter counts, and training-time metrics.
- Interpret ablation studies through visualizations and structured hypotheses.

---

## What You'll Work Through

**Notebook**: `hw02_assignment.ipynb`

1. **Setup & Utilities**  
   Run the provided helper cell to load data-generation, preprocessing, model, training, and plotting utilities.

2. **Synthetic Data Generation**  
   Create three 1,000-step time series (seasonal, trend+noise, mixed) and visualize them.

3. **Quick Check (Easy)**  
   Inspect the shapes produced by the sliding-window dataset to confirm your understanding of lookback/forecast horizons.

4. **Model Registry**  
   Build a dictionary that maps model names to classes and compute parameter counts for each architecture.

5. **Ablation Loop**  
   For every dataset/model combination: prepare loaders, train with early stopping, evaluate on the test split, and store metrics.

6. **Results Summary**  
   Display `results_df`, export `ablation_results.csv`, and verify that plots/output files are generated.

7. **Visualization & Hypotheses**  
   Produce the included 2x2 comparison figure and interpret the three research hypotheses (H1–H3).

8. **Key Findings & Reflection**  
   Report the best model per dataset, efficiency comparisons, and answer short reflection prompts.

---

## Runtime Expectations

- Full execution (all nine experiments) may take 10–15 minutes on CPU.
- Visualizations rely on Matplotlib/Seaborn; ensure a backend is available when running headless.

