{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 - Part 3: Spectral Analysis of Fine-tuned Language Models\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this assignment, you will learn how to:\n",
    "1. Use **WeightWatcher** to analyze neural network weight matrices\n",
    "2. Understand the **power law exponent (Œ±)** as a measure of layer quality\n",
    "3. Track how model quality evolves during fine-tuning\n",
    "4. Interpret spectral analysis results\n",
    "\n",
    "## Background: What is WeightWatcher?\n",
    "\n",
    "**WeightWatcher** uses **Random Matrix Theory** to analyze the weight matrices in neural networks. It computes a metric called the **power law exponent (Œ±)** for each layer.\n",
    "\n",
    "### Understanding the Power Law Exponent (Œ±)\n",
    "\n",
    "Think of Œ± as a \"health score\" for each layer:\n",
    "\n",
    "- **Œ± between 2 and 6**: ‚úÖ **Healthy layer** - Well-trained, good generalization\n",
    "- **Œ± < 2**: ‚ö†Ô∏è **Over-trained** - Layer may be memorizing, not generalizing  \n",
    "- **Œ± > 6**: ‚ö†Ô∏è **Under-trained** - Layer needs more training\n",
    "\n",
    "### Why is this useful?\n",
    "\n",
    "Traditional metrics (like loss or accuracy) only tell you how well the model performs on data. The power law exponent tells you about the **internal quality** of the model:\n",
    "- Are layers learning good representations or just memorizing?\n",
    "- Which layers are well-trained vs problematic?\n",
    "- Is fine-tuning improving or degrading the model?\n",
    "\n",
    "## Assignment Tasks\n",
    "\n",
    "1. **Coding Task 1**: Calculate perplexity from loss (1 line of code)\n",
    "2. **Coding Task 2**: Create a simple visualization (2-3 lines of code)\n",
    "3. **Interpretation Questions**: Answer guided questions about the results\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "import requests\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# HuggingFace Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# WeightWatcher\n",
    "import weightwatcher as ww\n",
    "\n",
    "print(\"‚úì All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Configuration (lighter for faster execution)\n",
    "SEED = 42\n",
    "MODEL_NAME = \"distilgpt2\"  # 82M parameter model\n",
    "MAX_LENGTH = 256  # Shorter sequences for speed\n",
    "NUM_EPOCHS = 1  # Just 1 epoch for speed\n",
    "BATCH_SIZE = 8\n",
    "MAX_SAMPLES = 500  # Limit dataset size for speed\n",
    "OUTPUT_DIR = \"./finetuned_model_light\"\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Training {MODEL_NAME} for {NUM_EPOCHS} epoch with {MAX_SAMPLES} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Load and Prepare Dataset\n",
    "\n",
    "We'll use a subset of the **IR Triplets** dataset for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download IR Triplets dataset\n",
    "url = \"https://raw.githubusercontent.com/omroot/InductiveSLM/master/cache/raw_data/ir_triplets/ir_triplets.json\"\n",
    "print(f\"Downloading dataset...\")\n",
    "response = requests.get(url, timeout=20)\n",
    "data = response.json()\n",
    "\n",
    "# Take a subset for speed\n",
    "random.seed(SEED)\n",
    "data = random.sample(data, min(MAX_SAMPLES, len(data)))\n",
    "\n",
    "# Split into train/test\n",
    "test_size = int(0.2 * len(data))\n",
    "test_data = data[:test_size]\n",
    "train_data = data[test_size:]\n",
    "\n",
    "print(f\"‚úì Loaded {len(train_data)} train + {len(test_data)} test examples\")\n",
    "\n",
    "# Format for causal LM (combine Context + Question + Answer)\n",
    "def format_example(ex):\n",
    "    text = f\"Context: {ex['Training Observations']}\\n\\nQuestion: {ex['Question']}\\n\\nAnswer: {ex['Answer']}\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "train_formatted = [format_example(ex) for ex in train_data]\n",
    "test_formatted = [format_example(ex) for ex in test_data]\n",
    "\n",
    "print(f\"‚úì Formatted datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Load Model and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = model.to(device)\n",
    "print(f\"‚úì Model loaded: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "# Tokenize\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=MAX_LENGTH, padding=\"max_length\")\n",
    "\n",
    "train_dataset = Dataset.from_list(train_formatted).map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "test_dataset = Dataset.from_list(test_formatted).map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "print(f\"‚úì Datasets tokenized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Analyze Pre-trained Model with WeightWatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ANALYZING PRE-TRAINED MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run WeightWatcher\n",
    "watcher = ww.WeightWatcher(model=model.cpu())\n",
    "details_pre = watcher.analyze(plot=False)\n",
    "model.to(device)  # Move back to device\n",
    "\n",
    "# Extract metrics\n",
    "alpha_values_pre = details_pre['alpha'].tolist()\n",
    "alpha_mean_pre = np.mean(alpha_values_pre)\n",
    "n_layers = len(alpha_values_pre)\n",
    "n_good_layers_pre = sum(1 for a in alpha_values_pre if 2 <= a <= 6)\n",
    "\n",
    "print(f\"\\n‚úì Pre-trained model analysis:\")\n",
    "print(f\"  Layers analyzed: {n_layers}\")\n",
    "print(f\"  Mean Œ±: {alpha_mean_pre:.3f}\")\n",
    "print(f\"  Good layers (2 ‚â§ Œ± ‚â§ 6): {n_good_layers_pre}/{n_layers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FINE-TUNING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=20,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    seed=SEED,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train\n",
    "train_result = trainer.train()\n",
    "print(f\"\\n‚úì Training complete! Training loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "test_loss = test_results['eval_loss']\n",
    "print(f\"  Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ CODING TASK 1: Calculate Perplexity\n",
    "\n",
    "### Background\n",
    "\n",
    "**Perplexity** measures how \"surprised\" the model is by the test data.\n",
    "- **Lower perplexity** = Better model\n",
    "- **Formula**: perplexity = exp(loss)\n",
    "\n",
    "### Your Task\n",
    "\n",
    "Complete the code below to calculate test perplexity.\n",
    "\n",
    "**Hint**: Use `np.exp(test_loss)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate perplexity from test_loss\n",
    "# Replace None with your code\n",
    "test_perplexity = None  # YOUR CODE HERE\n",
    "\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")\n",
    "print(f\"Interpretation: Lower is better. Perfect model = 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Analyze Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ANALYZING FINE-TUNED MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run WeightWatcher on fine-tuned model\n",
    "watcher_post = ww.WeightWatcher(model=model.cpu())\n",
    "details_post = watcher_post.analyze(plot=False)\n",
    "model.to(device)\n",
    "\n",
    "# Extract metrics\n",
    "alpha_values_post = details_post['alpha'].tolist()\n",
    "alpha_mean_post = np.mean(alpha_values_post)\n",
    "n_good_layers_post = sum(1 for a in alpha_values_post if 2 <= a <= 6)\n",
    "\n",
    "print(f\"\\n‚úì Fine-tuned model analysis:\")\n",
    "print(f\"  Layers analyzed: {len(alpha_values_post)}\")\n",
    "print(f\"  Mean Œ±: {alpha_mean_post:.3f}\")\n",
    "print(f\"  Good layers (2 ‚â§ Œ± ‚â§ 6): {n_good_layers_post}/{len(alpha_values_post)}\")\n",
    "\n",
    "print(f\"\\nChange from pre-trained to fine-tuned:\")\n",
    "print(f\"  ŒîŒ± = {alpha_mean_post - alpha_mean_pre:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Create Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "summary_data = [\n",
    "    {\n",
    "        'Stage': 'Pre-trained',\n",
    "        'Mean Œ±': f\"{alpha_mean_pre:.3f}\",\n",
    "        'Good Layers': f\"{n_good_layers_pre}/{n_layers}\",\n",
    "        'Test Loss': 'N/A',\n",
    "        'Perplexity': 'N/A'\n",
    "    },\n",
    "    {\n",
    "        'Stage': 'Fine-tuned',\n",
    "        'Mean Œ±': f\"{alpha_mean_post:.3f}\",\n",
    "        'Good Layers': f\"{n_good_layers_post}/{len(alpha_values_post)}\",\n",
    "        'Test Loss': f\"{test_loss:.4f}\",\n",
    "        'Perplexity': f\"{test_perplexity:.2f}\" if test_perplexity is not None else 'N/A'\n",
    "    }\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ CODING TASK 2: Create a Simple Bar Chart\n",
    "\n",
    "### Background\n",
    "\n",
    "Let's visualize how the mean Œ± changed from pre-trained to fine-tuned.\n",
    "\n",
    "### Your Task\n",
    "\n",
    "Complete the code below to create a bar chart comparing the two Œ± values.\n",
    "\n",
    "**Hint**: Use `plt.bar(['Pre-trained', 'Fine-tuned'], [value1, value2])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a bar chart comparing alpha_mean_pre and alpha_mean_post\n",
    "# Replace None with your code\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(None, None)  # YOUR CODE HERE: ['Pre-trained', 'Fine-tuned'], [alpha_mean_pre, alpha_mean_post]\n",
    "\n",
    "plt.axhline(y=2, color='green', linestyle='--', alpha=0.5, label='Healthy range')\n",
    "plt.axhline(y=6, color='green', linestyle='--', alpha=0.5)\n",
    "plt.ylabel('Mean Œ±', fontsize=12)\n",
    "plt.title('Power Law Exponent Before and After Fine-tuning', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('alpha_comparison.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization saved as 'alpha_comparison.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù INTERPRETATION QUESTIONS\n",
    "\n",
    "Answer the following questions based on your results.\n",
    "\n",
    "### Question 1: Understanding Œ±\n",
    "\n",
    "**Q1a**: What was the mean Œ± for the pre-trained DistilGPT2 model?\n",
    "\n",
    "**Your answer**: [Write your answer here]\n",
    "\n",
    "**Q1b**: Is this in the \"healthy\" range (2-6)? What does this tell you?\n",
    "\n",
    "**Your answer**: [Write your answer here]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Changes During Training\n",
    "\n",
    "**Q2a**: Did the mean Œ± increase, decrease, or stay approximately the same after fine-tuning?\n",
    "\n",
    "**Your answer**: [Write your answer here]\n",
    "\n",
    "**Q2b**: What do you think this means about the quality of fine-tuning?\n",
    "\n",
    "**Your answer**: [Write your answer here]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Practical Application\n",
    "\n",
    "**Q3**: Imagine you're training a model and you see Œ± values dropping below 2 for many layers. Based on what you learned, what would this indicate and what might you do about it?\n",
    "\n",
    "**Your answer**: [2-3 sentences]\n",
    "\n",
    "*Hint: Remember what Œ± < 2 means!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed the spectral analysis assignment!\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. ‚úÖ How to use WeightWatcher to analyze models\n",
    "2. ‚úÖ What power law exponent (Œ±) means and how to interpret it\n",
    "3. ‚úÖ How to calculate perplexity from loss\n",
    "4. ‚úÖ How to visualize spectral analysis results\n",
    "5. ‚úÖ Practical applications of this method\n",
    "\n",
    "### How to Reuse This Method\n",
    "\n",
    "You can use this same approach on ANY PyTorch model:\n",
    "\n",
    "```python\n",
    "import weightwatcher as ww\n",
    "\n",
    "# Analyze any model!\n",
    "watcher = ww.WeightWatcher(model=your_model)\n",
    "details = watcher.analyze(plot=False)\n",
    "alpha_values = details['alpha'].tolist()\n",
    "mean_alpha = np.mean(alpha_values)\n",
    "print(f\"Mean Œ±: {mean_alpha:.3f}\")\n",
    "```\n",
    "\n",
    "### Submission\n",
    "\n",
    "Submit this completed notebook with:\n",
    "1. Both coding tasks completed\n",
    "2. All interpretation questions answered\n",
    "3. All cells executed (with outputs visible)\n",
    "\n",
    "**Good luck!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
